{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b886bbd4-192c-42a2-b25b-47c4d7e8ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import abc\n",
    "import yaml\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5af390-79b3-4dbc-ac47-c4f66139ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yaml_reader():\n",
    "    with open(\"config.yaml\",\"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6119ccd-aa10-4a52-a5d2-f694140a6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml_reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f826ad71-8ead-4591-9c44-6df4c9aa59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdir = config[\"dataset_parameters\"][\"testdir\"] #This is where dataset located. Change it to the relevant.\n",
    "traindir = config[\"dataset_parameters\"][\"traindir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e14d9c-7424-4468-9104-359d54524412",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_learning = config[\"training_parameters\"][\"learning_rate\"]\n",
    "epochs = config[\"training_parameters\"][\"num_epochs\"]  # After 30th epoch we can see the beginning of overfitting at this parameters. I guess there could be a bit more complexity of model than it need.\n",
    "bs = config[\"training_parameters\"][\"batch_size\"] # Change this parameter according to hardware.\n",
    "dropout_rate = config[\"model_parameters\"][\"dropout_rate\"] #A little bit increase of this probabilty will occur as bad converge\n",
    "wd = config[\"model_parameters\"][\"weight_decay\"] # Weight decay for weight regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c341f2b2-e3ca-4796-9a4a-f75a2cd20985",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(traindir).to_numpy()\n",
    "data_test = pd.read_csv(testdir).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "179fc42b-6d48-4098-93c8-f67ec161e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor():\n",
    "    def __init__(self, value: float):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.val = value\n",
    "        self.grads_list = []\n",
    "\n",
    "    def flatten(self):\n",
    "        return np.array(self.val).reshape(-1)\n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return f\"{self.val}\"\n",
    "    def __add__(self, obj) -> float:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.val + obj.val\n",
    "    def __sub__(self, obj) -> float:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.val - obj.val\n",
    "    def __mul__(self, obj) -> float:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.val * obj.val\n",
    "    def __truediv__(self, obj) -> float:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.val / obj.val        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10808813-028e-43d3-9a77-d10263ca5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(abc.ABC):\n",
    "    @abc.abstractclassmethod\n",
    "    def __init__(self, heigth: int, width: int):\n",
    "        pass\n",
    "    def __call__(self, input: np.ndarray) -> np.ndarray:\n",
    "        return self._call(input)\n",
    "        \n",
    "    @abc.abstractclassmethod\n",
    "    def _call(self, input: np.ndarray):\n",
    "        pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faea9113-d92e-4a6c-8951-6b2b597cf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(Layer):\n",
    "    def __init__(self, heigth: int, width: int, var=1) -> None:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.weights = np.random.normal(0, var, size=(heigth, width))\n",
    "    def _call(self, input: Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if (len(input.shape)) > 1:\n",
    "            input = input.flatten()\n",
    "        return input@self.weights\n",
    "    def __str__(self) -> None:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return f\"{self.weights}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b1d8ab-470d-45af-9681-685507783c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction(abc.ABC):\n",
    "    @abc.abstractclassmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, input: np.ndarray) -> np.ndarray:\n",
    "        return self._call(input)\n",
    "    @abc.abstractclassmethod\n",
    "    def _call(self, input: np.ndarray):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4e93e02-3f7c-4759-8346-28afb0c3608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(ActivationFunction):\n",
    "    def __init__(self: ActivationFunction):\n",
    "        return\n",
    "    def _call(self: ActivationFunction, input: np.ndarray) -> np.ndarray:\n",
    "        vect_relu = np.vectorize(self.relu)\n",
    "        return vect_relu(input)\n",
    "\n",
    "    def relu(self, x):\n",
    "        return x if x > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "045eb3d4-7bbb-4aa5-a8ad-925143799bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(ActivationFunction):\n",
    "    def __init__(self: ActivationFunction):\n",
    "        return\n",
    "    def _call(self:ActivationFunction, input: np.ndarray) -> np.ndarray:\n",
    "        input = input.reshape(-1)\n",
    "        exp_input = sum(np.exp(input))\n",
    "        return [np.exp(x)/exp_input for x in input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09a4b9f4-6aa8-4b6d-b1b3-02ab6ec12325",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistClassifier():\n",
    "    def __init__(self, list_of_layers): \n",
    "        self.architecture = list_of_layers \n",
    "    def __call__(self, x):\n",
    "        return reduce(lambda acc, func: func(acc), self.architecture, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42a36d4a-4450-488d-a423-97a675fd7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(Layer):\n",
    "    def __init__(self, in_channel: int, out_channel:int, kernel_size: list = [2,2], var: float =1.0):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.weights = np.random.normal(0, var, size=(out_channel, in_channel, kernel_size[0], kernel_size[1]))\n",
    "\n",
    "    def get_image_sector(self, image: np.ndarray, j: int, k: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        sector = image[j:j+self.kernel_size[0],k:k+self.kernel_size[1]]\n",
    "        return sector.reshape(-1)\n",
    "\n",
    "    def _call(self, input: np.ndarray) -> np.ndarray:\n",
    "        self.img_h, self.img_w = input.shape[-2:]\n",
    "        try:\n",
    "            input = input.reshape(-1, self.in_channel, self.img_w, self.img_h)\n",
    "        except e:\n",
    "            print(e)\n",
    "            return\n",
    "        self.batch_size = input.shape[0]\n",
    "        return self.conv(input)\n",
    "    \n",
    "    def conv(self, images: np.ndarray) -> np.ndarray:\n",
    "        conved_image = np.zeros([self.batch_size, self.out_channel, self.img_h-self.kernel_size[0]+1, self.img_w-self.kernel_size[1]+1])\n",
    "        for i, img in enumerate(images):\n",
    "            for j, out_filter in enumerate(self.weights):\n",
    "                in_channels_array = []\n",
    "                for k, in_filter in enumerate(out_filter):\n",
    "                    sector_channel = self.crop_image_sector(img[k])\n",
    "                    proccesed_image_separate = np.zeros([len(sector_channel), 1])\n",
    "                    for l, sector in enumerate(sector_channel):\n",
    "                        proccesed_image_separate[l] = np.sum(np.dot(sector.reshape(self.kernel_size), in_filter))\n",
    "                    in_channels_array.append(proccesed_image_separate)\n",
    "                in_channels_array = np.array(in_channels_array)\n",
    "                conved_image[i] = np.sum(in_channels_array, axis=0).reshape(self.img_h-self.kernel_size[0]+1, self.img_w-self.kernel_size[1]+1)\n",
    "        return conved_image\n",
    "            \n",
    "\n",
    "    def crop_image_sector(self, image: np.ndarray) -> list:\n",
    "        sectors = []\n",
    "        for j in range(self.img_h):\n",
    "            for k in range(self.img_w):\n",
    "                sectors.append(self.get_image_sector(image, j, k))\n",
    "            sectors = [list(sector) for sector in sectors if len(sector) >= np.prod(self.kernel_size)]\n",
    "        return np.array(sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3af13b0-2d3b-44ed-9518-43eb00b4e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm2d(Layer):\n",
    "    def __init__(self, channels: int):\n",
    "        self.betas = np.random.random([1, channels])\n",
    "        self.gammas = np.random.random([1, channels])\n",
    "        self.mean = 0\n",
    "        self.std = 0\n",
    "        self.eps = 1e-6\n",
    "        self.channels = channels\n",
    "        self.batch_normalize = np.vectorize(self.normalize)\n",
    "    def _call(self, input:np.ndarray):\n",
    "        self.calculate_mean()\n",
    "        self.calculate_std()\n",
    "        return self.batch_normalize(input)\n",
    "\n",
    "    def calculate_mean(self, input:np.ndarray) -> None:\n",
    "        self.mean = np.mean(input)\n",
    "\n",
    "    def calculate_std(self, input:np.ndarray) -> None:\n",
    "        self.std = np.std(input)\n",
    "\n",
    "    def normalize(self, x):\n",
    "        for i in range(self.channels):\n",
    "            x = self.gammas[i]+self.betas[i]*(x - self.mean)/(self.std+self.eps)\n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e241936b-d087-4593-b083-6e0f0b80ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2d(Layer):\n",
    "    def __init__(self, heigth: int, width: int, in_channel: int) -> None:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.kernel_size = [heigth, width]\n",
    "        self.in_channel = in_channel\n",
    "\n",
    "    def _call(self, input: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.img_h, self.img_w = input.shape[-2:]\n",
    "        try:\n",
    "            input = input.reshape(-1, self.in_channel, self.img_w, self.img_h)\n",
    "        except e:\n",
    "            print(e)\n",
    "            return\n",
    "        self.batch_size = input.shape[0]\n",
    "        self.out_h, self.out_w = self.calculate_out_shape()\n",
    "        out = np.array(self.pool(input))\n",
    "        return out.reshape(self.batch_size, self.in_channel, self.out_h, self.out_w)\n",
    "\n",
    "    def calculate_out_shape(self):\n",
    "        if self.img_h%self.kernel_size[0] == 0:\n",
    "            out_h = self.img_h//self.kernel_size[0]\n",
    "        else:\n",
    "            out_h = self.img_h//self.kernel_size[0] + 1\n",
    "        if self.img_w%self.kernel_size[1] == 0:\n",
    "            out_w = self.img_w // self.kernel_size[1]\n",
    "        else:\n",
    "            out_w = self.img_w // self.kernel_size[1] + 1\n",
    "        return out_h, out_w\n",
    "            \n",
    "    def get_image_sector(self, image: np.ndarray, j: int, k: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        sector = image[j*self.kernel_size[0]:(j+1)*self.kernel_size[0],k*self.kernel_size[1]:(k+1)*self.kernel_size[1]]\n",
    "        return sector.reshape(-1)\n",
    "\n",
    "    def pool(self, images: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        out = np.zeros([self.batch_size, self.in_channel, self.out_h, self.out_w])\n",
    "        for i, img in enumerate(images):\n",
    "            sectors = []\n",
    "            for l in range(self.in_channel):\n",
    "                for j in range(self.img_h):\n",
    "                    for k in range(self.img_w):\n",
    "                        sectors.append(self.get_image_sector(img[l], j, k))\n",
    "            sectors = [sector.tolist() for sector in sectors if sector.size > 0]\n",
    "            max_sectors = np.array([max(sector) for sector in sectors])\n",
    "            out[i] = max_sectors.reshape(self.in_channel, self.out_h, self.out_w)\n",
    "        return out\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80ba172f-71ff-4096-b062-3e9ba7bb6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistClassifier([\n",
    "    Conv2d(in_channel=1, out_channel=3),\n",
    "    MaxPool2d(2,2, in_channel=3),\n",
    "    ReLU(),\n",
    "    Conv2d(in_channel=3, out_channel=16),\n",
    "    MaxPool2d(2,2, in_channel=16),\n",
    "    ReLU(),\n",
    "    Conv2d(in_channel=16, out_channel=32),\n",
    "    MaxPool2d(2,2, in_channel=32),\n",
    "    ReLU(),\n",
    "    Conv2d(in_channel=32, out_channel=64),\n",
    "    MaxPool2d(2,2, in_channel=64),\n",
    "    ReLU(),\n",
    "    FC(192, 32),\n",
    "    ReLU(),\n",
    "    FC(32, 10),\n",
    "    Softmax()\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87fcf7ee-4222-43ea-9947-31453f6d0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.random.randint(0, 255, size=(1, 3, 29, 29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0770897e-f05d-4c87-8fae-413e97d4855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9840/1149701116.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  exp_input = sum(np.exp(input))\n",
      "/tmp/ipykernel_9840/1149701116.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  return [np.exp(x)/exp_input for x in input]\n",
      "/tmp/ipykernel_9840/1149701116.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return [np.exp(x)/exp_input for x in input]\n"
     ]
    }
   ],
   "source": [
    "predict = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daad14d-d851-43be-bda2-d637e7cde7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
